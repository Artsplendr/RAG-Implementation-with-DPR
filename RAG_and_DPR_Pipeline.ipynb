{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovtRPGnBClBp"
      },
      "source": [
        "# Building a Retrieval-Augmented Generation (RAG) with Dense Passage Retrieval (DPR) pipeline using Python\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6_EK-OC8Hj"
      },
      "source": [
        "## Description\n",
        "The goal of this experiment is to implement a simple Retrieval-Augmented Generation (RAG) with Dense Passage Retrieval (DPR) pipeline to answer user queries by combining the strengths of dense passage retrieval for fetching relevant documents and generative models for answering queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogBqRbYYFi5Q"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ9MCP86FwVv",
        "outputId": "eb0d84a2-d888-4d3d-f4d9-3adc81bbc8cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"YOUR-PATH-HERE\""
      ],
      "metadata": {
        "id": "cZykBPye212L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i4rA3qWClBt",
        "collapsed": true
      },
      "source": [
        "# Install necessary libraries\n",
        "%%capture\n",
        "!pip install transformers faiss-cpu datasets sentence-transformers\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import faiss\n",
        "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
        "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
        "from transformers import pipeline\n",
        "import re"
      ],
      "metadata": {
        "id": "D5QzCSiw7HX0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents. Example dataset\n",
        "documents = [\n",
        "    \"Stars appear to twinkle because their light passes through Earth’s atmosphere before reaching our eyes.\",\n",
        "    \"The air in the atmosphere is always moving, and this bends the light in different directions.\",\n",
        "    \"This bending makes the star’s light seem to change in brightness and position, creating the twinkling effect.\",\n",
        "    \"If you were to see a star from space, where there is no atmosphere, it wouldn’t twinkle at all!\",\n",
        "    \"Planets, however, usually do not twinkle as much because they appear larger in the sky and their light is more stable.\"\n",
        "]\n",
        "\n",
        "doc_df = pd.DataFrame(documents, columns=[\"text\"])"
      ],
      "metadata": {
        "id": "_prxTiA3uTrW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create document embeddings\n",
        "\n",
        "# Load DPR context encoder and tokenizer\n",
        "%%capture\n",
        "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "\n",
        "# Generate embeddings for documents\n",
        "def generate_embeddings(documents):\n",
        "    inputs = ctx_tokenizer(documents, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        embeddings = ctx_encoder(**inputs).pooler_output\n",
        "    return embeddings\n",
        "\n",
        "document_embeddings = generate_embeddings(doc_df[\"text\"].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Gy5fPY6PuTt_",
        "outputId": "342bdad5-a1ed-44af-8036-8195255fb825"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the Embeddings Using FAISS\n",
        "# Convert embeddings to numpy\n",
        "document_embeddings_np = document_embeddings.numpy()\n",
        "\n",
        "# Create FAISS index\n",
        "dimension = document_embeddings_np.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)  # Inner product for similarity\n",
        "index.add(document_embeddings_np)\n",
        "\n",
        "print(f\"Number of documents indexed: {index.ntotal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfcNSkhGuTwE",
        "outputId": "70ad9b85-3dd5-4f5f-a8cf-85f7a1e10403"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents indexed: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the top-k most relevant documents for a user query\n",
        "\n",
        "# Load DPR question encoder and tokenizer\n",
        "%%capture\n",
        "query_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n",
        "query_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n",
        "\n",
        "# Function to retrieve documents\n",
        "def retrieve_documents(query, top_k=2):\n",
        "    # Encode the query\n",
        "    inputs = query_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        query_embedding = query_encoder(**inputs).pooler_output.numpy()\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    results = [(doc_df[\"text\"].iloc[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5DUzOCjPuTyM",
        "outputId": "746987dc-d5eb-4813-c07c-b87b1343cce4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-question_encoder-multiset-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query\n",
        "query = \"Why do stars twinkle (also called stellar scintillation) in the night sky?\"\n",
        "retrieved_docs = retrieve_documents(query)\n",
        "print(\"Retrieved Documents:\", retrieved_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B6VRBQT1uT0x",
        "outputId": "91c4b2b9-f693-4ff7-cca3-667301bc9319"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Documents: [('Planets, however, usually do not twinkle as much because they appear larger in the sky and their light is more stable.', 74.23694), ('Stars appear to twinkle because their light passes through Earth’s atmosphere before reaching our eyes.', 72.949875)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate an Answer Using a Language Model\n",
        "\n",
        "# Load a generative model\n",
        "generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large\")\n",
        "\n",
        "# Generate an answer\n",
        "def generate_answer(query, retrieved_docs):\n",
        "    context = \" \".join([doc[0] for doc in retrieved_docs])  # Combine top-k docs\n",
        "    prompt = f\"{context}\"\n",
        "\n",
        "    answer = generator(prompt, max_length=50, num_beams=3)[0][\"generated_text\"]\n",
        "\n",
        "    # Format and display the results\n",
        "    display_result(query, answer)\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HjBpKZiWx6kK",
        "outputId": "839895ad-d78d-4b31-88c9-6c9219734e70"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to format and display results\n",
        "def display_result(query, answer):\n",
        "    print(\"\\n=== Query ===\")\n",
        "    print(query)  # Print the retriever query\n",
        "\n",
        "    print(\"\\n=== Answer ===\")\n",
        "    sentences = re.split(r'(?<=\\.) ', answer)\n",
        "    for sentence in sentences:\n",
        "        print(sentence.strip())  # Print each sentence on a new line"
      ],
      "metadata": {
        "id": "SbZFuGBuy7IB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "answer = generate_answer(query, retrieved_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsOA8SVhx6tg",
        "outputId": "9a1c81a8-4f25-4963-e256-4230f19dd467"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Query ===\n",
            "Why do stars twinkle (also called stellar scintillation) in the night sky?\n",
            "\n",
            "=== Answer ===\n",
            "Planets, however, usually do not twinkle as much because they appear larger in the sky and their light is more stable.\n",
            "Stars appear to twinkle because their light passes through Earth’s atmosphere before reaching our eyes.\n"
          ]
        }
      ]
    }
  ]
}